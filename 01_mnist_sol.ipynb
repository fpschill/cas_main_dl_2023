{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HdIyPPHlWR83",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Hello World in Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DJHomXq8vevZ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Exercise \n",
    "\n",
    "Train the same neural network with fewer and more training data. train with 100,1000 and the full training data. Look at the learning curves of each model and evaluate the performace on the test dataset, what do you observe? Play around with the nr of the hidden layer and with the nr of nodes. What do you observe?  \n",
    "*Hint: You might need to train for more than just 10 epochs*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1rQcTySXNZ1p",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Train with 100 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HmRUaXJ1WfLO",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tensorflow.keras.models import Sequential, Model, clone_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HJYc7BYtvevd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(x_digits_train, y_digits_train), (x_digits_test, y_digits_test) = mnist.load_data()\n",
    "\n",
    "# Make train data smaller\n",
    "np.random.seed(36)\n",
    "train_data_idx=np.random.choice(range(0,len(x_digits_train)),100,replace=False)\n",
    "x_digits_train=x_digits_train[train_data_idx]\n",
    "y_digits_train=y_digits_train[train_data_idx]\n",
    "print(x_digits_train.shape)\n",
    "# Preprocess data \n",
    "x_digits_train = x_digits_train.astype('float32')\n",
    "x_digits_test = x_digits_test.astype('float32')\n",
    "x_digits_train = x_digits_train/ 255\n",
    "x_digits_test = x_digits_test/ 255\n",
    "y_digits_train = to_categorical(y_digits_train, 10)\n",
    "y_digits_test = to_categorical(y_digits_test, 10)\n",
    "x_digits_train=x_digits_train.reshape((len(x_digits_train),28,28,1))\n",
    "x_digits_test=x_digits_test.reshape((len(x_digits_test),28,28,1))\n",
    "\n",
    "\n",
    "# Define model \n",
    "model_digits = Sequential()\n",
    "model_digits.add(Flatten(input_shape=(28,28,1)))\n",
    "model_digits.add(Dense(500, activation='relu'))\n",
    "model_digits.add(Dense(50, activation='relu'))\n",
    "model_digits.add(Dense(10, activation='softmax'))\n",
    "# Compile model\n",
    "model_digits.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "history=model_digits.fit(x_digits_train, y_digits_train,validation_data=(x_digits_test, y_digits_test),\n",
    "                         batch_size=128, epochs=20, verbose=1)\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='lower right')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "model_digits.evaluate(x_digits_test,y_digits_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dyG4tdUkNZ1t",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Add layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LWletrpLvevf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(x_digits_train, y_digits_train), (x_digits_test, y_digits_test) = mnist.load_data()\n",
    "\n",
    "# Make train data smaller\n",
    "np.random.seed(36)\n",
    "train_data_idx=np.random.choice(range(0,len(x_digits_train)),100,replace=False)\n",
    "x_digits_train=x_digits_train[train_data_idx]\n",
    "y_digits_train=y_digits_train[train_data_idx]\n",
    "\n",
    "# Preprocess data \n",
    "x_digits_train = x_digits_train.astype('float32')\n",
    "x_digits_test = x_digits_test.astype('float32')\n",
    "x_digits_train = x_digits_train/ 255\n",
    "x_digits_test = x_digits_test/ 255\n",
    "y_digits_train = to_categorical(y_digits_train, 10)\n",
    "y_digits_test = to_categorical(y_digits_test, 10)\n",
    "x_digits_train=x_digits_train.reshape((len(x_digits_train),28,28,1))\n",
    "x_digits_test=x_digits_test.reshape((len(x_digits_test),28,28,1))\n",
    "\n",
    "\n",
    "# Define model \n",
    "model_digits = Sequential()\n",
    "model_digits.add(Flatten(input_shape=(28,28,1)))\n",
    "model_digits.add(Dense(500, activation='relu'))\n",
    "model_digits.add(Dense(200, activation='relu'))\n",
    "model_digits.add(Dense(100, activation='relu'))\n",
    "model_digits.add(Dense(50, activation='relu'))\n",
    "model_digits.add(Dense(10, activation='softmax'))\n",
    "# Compile model\n",
    "model_digits.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "history=model_digits.fit(x_digits_train, y_digits_train,validation_data=(x_digits_test, y_digits_test),\n",
    "                         batch_size=128, epochs=20, verbose=1)\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='lower right')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "model_digits.evaluate(x_digits_test,y_digits_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZOeLiEl-NZ1x",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Only one layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_n7xoMW8vevj",
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(x_digits_train, y_digits_train), (x_digits_test, y_digits_test) = mnist.load_data()\n",
    "\n",
    "# Make train data smaller\n",
    "np.random.seed(36)\n",
    "train_data_idx=np.random.choice(range(0,len(x_digits_train)),100,replace=False)\n",
    "x_digits_train=x_digits_train[train_data_idx]\n",
    "y_digits_train=y_digits_train[train_data_idx]\n",
    "\n",
    "# Preprocess data \n",
    "x_digits_train = x_digits_train.astype('float32')\n",
    "x_digits_test = x_digits_test.astype('float32')\n",
    "x_digits_train = x_digits_train/ 255\n",
    "x_digits_test = x_digits_test/ 255\n",
    "y_digits_train = to_categorical(y_digits_train, 10)\n",
    "y_digits_test = to_categorical(y_digits_test, 10)\n",
    "x_digits_train=x_digits_train.reshape((len(x_digits_train),28,28,1))\n",
    "x_digits_test=x_digits_test.reshape((len(x_digits_test),28,28,1))\n",
    "\n",
    "\n",
    "# Define model \n",
    "model_digits = Sequential()\n",
    "model_digits.add(Flatten(input_shape=(28,28,1)))\n",
    "model_digits.add(Dense(10, activation='softmax'))\n",
    "# Compile model\n",
    "model_digits.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "history=model_digits.fit(x_digits_train, y_digits_train,validation_data=(x_digits_test, y_digits_test),\n",
    "                         batch_size=128, epochs=50, verbose=1)\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='lower right')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "model_digits.evaluate(x_digits_test,y_digits_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0M-kRXd1NZ10",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1000 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1znkRuNSvevo",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(x_digits_train, y_digits_train), (x_digits_test, y_digits_test) = mnist.load_data()\n",
    "\n",
    "# Make train data smaller\n",
    "np.random.seed(43)\n",
    "train_data_idx=np.random.choice(range(0,len(x_digits_train)),1000,replace=False)\n",
    "x_digits_train=x_digits_train[train_data_idx]\n",
    "y_digits_train=y_digits_train[train_data_idx]\n",
    "\n",
    "# Preprocess data \n",
    "x_digits_train = x_digits_train.astype('float32')\n",
    "x_digits_test = x_digits_test.astype('float32')\n",
    "x_digits_train = x_digits_train/ 255\n",
    "x_digits_test = x_digits_test/ 255\n",
    "y_digits_train = to_categorical(y_digits_train, 10)\n",
    "y_digits_test = to_categorical(y_digits_test, 10)\n",
    "x_digits_train=x_digits_train.reshape((len(x_digits_train),28,28,1))\n",
    "x_digits_test=x_digits_test.reshape((len(x_digits_test),28,28,1))\n",
    "\n",
    "\n",
    "# Define model \n",
    "model_digits = Sequential()\n",
    "model_digits.add(Flatten(input_shape=(28,28,1)))\n",
    "model_digits.add(Dense(500, activation='relu'))\n",
    "model_digits.add(Dense(50, activation='relu'))\n",
    "model_digits.add(Dense(10, activation='softmax'))\n",
    "# Compile model\n",
    "model_digits.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "history=model_digits.fit(x_digits_train, y_digits_train,validation_data=(x_digits_test, y_digits_test),\n",
    "                         batch_size=128, epochs=20, verbose=1)\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='lower right')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "model_digits.evaluate(x_digits_test,y_digits_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQjnF25hNZ13",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### More epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3cQ2AQGsvevr",
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(x_digits_train, y_digits_train), (x_digits_test, y_digits_test) = mnist.load_data()\n",
    "\n",
    "# Make train data smaller\n",
    "np.random.seed(43)\n",
    "train_data_idx=np.random.choice(range(0,len(x_digits_train)),1000,replace=False)\n",
    "x_digits_train=x_digits_train[train_data_idx]\n",
    "y_digits_train=y_digits_train[train_data_idx]\n",
    "\n",
    "# Preprocess data \n",
    "x_digits_train = x_digits_train.astype('float32')\n",
    "x_digits_test = x_digits_test.astype('float32')\n",
    "x_digits_train = x_digits_train/ 255\n",
    "x_digits_test = x_digits_test/ 255\n",
    "y_digits_train = to_categorical(y_digits_train, 10)\n",
    "y_digits_test = to_categorical(y_digits_test, 10)\n",
    "x_digits_train=x_digits_train.reshape((len(x_digits_train),28,28,1))\n",
    "x_digits_test=x_digits_test.reshape((len(x_digits_test),28,28,1))\n",
    "\n",
    "\n",
    "# Define model \n",
    "model_digits = Sequential()\n",
    "model_digits.add(Flatten(input_shape=(28,28,1)))\n",
    "model_digits.add(Dense(10, activation='softmax'))\n",
    "# Compile model\n",
    "model_digits.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "history=model_digits.fit(x_digits_train, y_digits_train,validation_data=(x_digits_test, y_digits_test),\n",
    "                         batch_size=128, epochs=40, verbose=1)\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='lower right')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "model_digits.evaluate(x_digits_test,y_digits_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yEGyv5r9NZ15",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tHjBk1OMvevu",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(x_digits_train, y_digits_train), (x_digits_test, y_digits_test) = mnist.load_data()\n",
    "\n",
    "# Make train data smaller\n",
    "#np.random.seed(43)\n",
    "#train_data_idx=np.random.choice(range(0,len(x_digits_train)),1000,replace=False)\n",
    "#x_digits_train=x_digits_train[train_data_idx]\n",
    "#y_digits_train=y_digits_train[train_data_idx]\n",
    "\n",
    "# Preprocess data \n",
    "x_digits_train = x_digits_train.astype('float32')\n",
    "x_digits_test = x_digits_test.astype('float32')\n",
    "x_digits_train = x_digits_train/ 255\n",
    "x_digits_test = x_digits_test/ 255\n",
    "y_digits_train = to_categorical(y_digits_train, 10)\n",
    "y_digits_test = to_categorical(y_digits_test, 10)\n",
    "x_digits_train=x_digits_train.reshape((len(x_digits_train),28,28,1))\n",
    "x_digits_test=x_digits_test.reshape((len(x_digits_test),28,28,1))\n",
    "\n",
    "\n",
    "# Define model \n",
    "model_digits = Sequential()\n",
    "model_digits.add(Flatten(input_shape=(28,28,1)))\n",
    "model_digits.add(Dense(500, activation='relu'))\n",
    "model_digits.add(Dense(50, activation='relu'))\n",
    "model_digits.add(Dense(10, activation='softmax'))\n",
    "# Compile model\n",
    "model_digits.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "history=model_digits.fit(x_digits_train, y_digits_train,validation_data=(x_digits_test, y_digits_test),\n",
    "                         batch_size=128, epochs=10, verbose=1)\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='lower right')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "model_digits.evaluate(x_digits_test,y_digits_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jCMCSTiXvevw",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(x_digits_train, y_digits_train), (x_digits_test, y_digits_test) = mnist.load_data()\n",
    "\n",
    "# Make train data smaller\n",
    "#np.random.seed(43)\n",
    "#train_data_idx=np.random.choice(range(0,len(x_digits_train)),1000,replace=False)\n",
    "#x_digits_train=x_digits_train[train_data_idx]\n",
    "#y_digits_train=y_digits_train[train_data_idx]\n",
    "\n",
    "# Preprocess data \n",
    "x_digits_train = x_digits_train.astype('float32')\n",
    "x_digits_test = x_digits_test.astype('float32')\n",
    "x_digits_train = x_digits_train/ 255\n",
    "x_digits_test = x_digits_test/ 255\n",
    "y_digits_train = to_categorical(y_digits_train, 10)\n",
    "y_digits_test = to_categorical(y_digits_test, 10)\n",
    "x_digits_train=x_digits_train.reshape((len(x_digits_train),28,28,1))\n",
    "x_digits_test=x_digits_test.reshape((len(x_digits_test),28,28,1))\n",
    "\n",
    "\n",
    "# Define model \n",
    "model_digits = Sequential()\n",
    "model_digits.add(Flatten(input_shape=(28,28,1)))\n",
    "model_digits.add(Dense(10, activation='softmax'))\n",
    "# Compile model\n",
    "model_digits.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "history=model_digits.fit(x_digits_train, y_digits_train,validation_data=(x_digits_test, y_digits_test),\n",
    "                         batch_size=128, epochs=10, verbose=1)\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='lower right')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "model_digits.evaluate(x_digits_test,y_digits_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m_V3DgJmNZ19",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### More layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iBvzBbXkvevy",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(x_digits_train, y_digits_train), (x_digits_test, y_digits_test) = mnist.load_data()\n",
    "\n",
    "# Make train data smaller\n",
    "#np.random.seed(43)\n",
    "#train_data_idx=np.random.choice(range(0,len(x_digits_train)),1000,replace=False)\n",
    "#x_digits_train=x_digits_train[train_data_idx]\n",
    "#y_digits_train=y_digits_train[train_data_idx]\n",
    "\n",
    "# Preprocess data \n",
    "x_digits_train = x_digits_train.astype('float32')\n",
    "x_digits_test = x_digits_test.astype('float32')\n",
    "x_digits_train = x_digits_train/ 255\n",
    "x_digits_test = x_digits_test/ 255\n",
    "y_digits_train = to_categorical(y_digits_train, 10)\n",
    "y_digits_test = to_categorical(y_digits_test, 10)\n",
    "x_digits_train=x_digits_train.reshape((len(x_digits_train),28,28,1))\n",
    "x_digits_test=x_digits_test.reshape((len(x_digits_test),28,28,1))\n",
    "\n",
    "\n",
    "# Define model \n",
    "model_digits = Sequential()\n",
    "model_digits.add(Flatten(input_shape=(28,28,1)))\n",
    "model_digits.add(Dense(500, activation='relu'))\n",
    "model_digits.add(Dense(400, activation='relu'))\n",
    "model_digits.add(Dense(200, activation='relu'))\n",
    "model_digits.add(Dense(100, activation='relu'))\n",
    "model_digits.add(Dense(10, activation='softmax'))\n",
    "# Compile model\n",
    "model_digits.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "history=model_digits.fit(x_digits_train, y_digits_train,validation_data=(x_digits_test, y_digits_test),\n",
    "                         batch_size=128, epochs=10, verbose=1)\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='lower right')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "model_digits.evaluate(x_digits_test,y_digits_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-6aQR9mHNZ1_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "01_notebook_sol.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
