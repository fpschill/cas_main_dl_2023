{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_DZIdUFTT2cn",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Cifar10 with MC-Dropout\n",
    "\n",
    "In this notebook we will use the cifar 10 dataset. We will use only 5 of the 10 labels to train two models. In the first one we use dropout at training time but not at test. The second model uses dropout not only in the training but also at test-time. The labels for the training will only be airplane, automobile, bird, cat and deer but we will predict all ten labels! The goal is to find a method to distinguish between known and unknown labels or at least to know which predictions are not certain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B0xfR5BHHQ-f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import tensorflow as tf\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B9d-6FsZHQ-k",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YbYNZP-w03tg",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Make train and testset smaller\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "922_CavJHQ-n",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#for trainset\n",
    "#loop over each class label and sample random images over each label and save the idx to subset\n",
    "np.random.seed(seed=220)\n",
    "idx = np.empty(0,dtype=\"int8\")\n",
    "for i in range(0,len(np.unique(y_train))):\n",
    "    idx = np.append(idx, np.random.choice(np.where((y_train[0:len(y_train)])==i)[0],\n",
    "                                          5000, replace=False))\n",
    "\n",
    "x_train = x_train[idx]\n",
    "y_train = y_train[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LS5aeVaeHQ-r",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#for testset\n",
    "#loop over each class label and sample random images over each label and save the idx to subset\n",
    "np.random.seed(seed=220)\n",
    "idx = np.empty(0,dtype=\"int8\")\n",
    "for i in range(0,len(np.unique(y_test))):\n",
    "    idx = np.append(idx,np.random.choice(np.where((y_test[0:len(y_test)])==i)[0],\n",
    "                                         500,replace=False))\n",
    "\n",
    "x_test = x_test[idx]\n",
    "y_test = y_test[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CbENZE2LHQ-t",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(np.unique(y_train,return_counts=True))\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(np.unique(y_test,return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wxtdHEfCHQ-1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels = np.array([\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "72tPPcsbHQ-4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#sample image of each label\n",
    "plt.figure(figsize=(20,20))\n",
    "for i in range(0,len(np.unique(y_train))):\n",
    "    rmd=np.random.choice(np.where(y_train==i)[0],1)\n",
    "    plt.subplot(1,10,i+1)\n",
    "    img=x_train[rmd]\n",
    "    plt.imshow(img[0,:,:,:])\n",
    "    plt.title(labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_YfUI4L03t0",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Delete all labels, except the first 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FmeL0LXjHQ-9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "idx = np.where(np.in1d(y_train,[5,6,7,8,9]))[0]\n",
    "x_train = np.delete(x_train, idx, axis=0)\n",
    "y_train = np.delete(y_train, idx, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BXFVOvXYHQ_G",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Hn4Dbnj03uC",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Normalize the train and testdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hY1OUkTEHQ_P",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_mean = np.mean( x_train, axis = 0)\n",
    "X_std = np.std( x_train, axis = 0)\n",
    "\n",
    "x_train = (x_train - X_mean ) / (X_std + 0.0001)\n",
    "x_test = (x_test - X_mean ) / (X_std + 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CJfoaSyoHQ_U",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(np.unique(y_train))\n",
    "labels[np.unique(y_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y9RWwAv-HQ_a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "y_train=to_categorical(y_train,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C4INbSbO03uP",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Split trainingdata into a train and validationset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DVfOklr1HQ_e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#make 80% train and 20% valid out of train\n",
    "np.random.seed(478)\n",
    "rand_idx = np.random.choice(list(range(0,len(x_train))),\n",
    "                            replace=False,\n",
    "                            size=round(0.8*(len(x_train))))\n",
    "len(rand_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W2-ubvnkHQ_l",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_valid = np.delete(x_train, axis=0, obj=rand_idx)\n",
    "y_valid = np.delete(y_train, axis=0, obj=rand_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pbYRoN0pHQ_p",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_train = x_train[rand_idx]\n",
    "y_train = y_train[rand_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ajhyRyWkHQ_r",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_valid.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "albTHMLaT2eJ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Define and train the models, one without and one with dropout at testtime.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8In6EbYkHQ_1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input,Lambda\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CK2iSq3THQ_3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.transpose(np.unique(np.argmax(y_train,axis=1), return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FQ3N0887JRVy",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# mc-dropout function\n",
    "def mcdrop(x, level=0.3):\n",
    "  return K.dropout(x, level=level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JHZBPX_dHQ_9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_mc = Sequential()\n",
    "\n",
    "\n",
    "model_mc.add(Convolution2D(32, (3,3),padding='same',input_shape=(32,32,3)))\n",
    "model_mc.add(Activation('relu'))\n",
    "model_mc.add(Lambda(mcdrop))\n",
    "model_mc.add(Convolution2D(32, (3,3),padding='same'))\n",
    "model_mc.add(Activation('relu'))\n",
    "model_mc.add(Lambda(mcdrop))\n",
    "model_mc.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_mc.add(Convolution2D(64, (3,3),padding='same'))\n",
    "model_mc.add(Activation('relu'))\n",
    "model_mc.add(Lambda(mcdrop))\n",
    "model_mc.add(Convolution2D(64, (3,3),padding='same'))\n",
    "model_mc.add(Activation('relu'))\n",
    "model_mc.add(Lambda(mcdrop))\n",
    "model_mc.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_mc.add(Flatten())\n",
    "model_mc.add(Lambda(mcdrop))\n",
    "model_mc.add(Dense(400))\n",
    "model_mc.add(Activation('relu'))\n",
    "model_mc.add(Lambda(mcdrop))\n",
    "model_mc.add(Dense(5))\n",
    "model_mc.add(Activation('softmax'))\n",
    "model_mc.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model_mc.summary()\n",
    "history1 = model_mc.fit(x_train,y_train,\n",
    "                    batch_size = 128,\n",
    "                    epochs = 15,  # 15\n",
    "                    validation_data = (x_valid, y_valid),\n",
    "                    verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KvgAaIkGUUeA",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Convolution2D(32, (3,3),padding='same',input_shape=(32,32,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(32, (3,3),padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Convolution2D(64, (3,3),padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, (3,3),padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(400))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "history2 = model.fit(x_train,y_train,\n",
    "                    batch_size=128,\n",
    "                    epochs = 15, #15\n",
    "                    validation_data = (x_valid, y_valid),\n",
    "                    verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AFqLgPjYHRAM",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history1.history['accuracy'])\n",
    "plt.plot(history1.history['val_accuracy'])\n",
    "plt.ylim(0, 1)\n",
    "plt.title('model accuracy mc')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='lower right')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history1.history['loss'])\n",
    "plt.plot(history1.history['val_loss'])\n",
    "plt.title('model loss mc')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history2.history['accuracy'])\n",
    "plt.plot(history2.history['val_accuracy'])\n",
    "plt.ylim(0, 1)\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='lower right')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history2.history['loss'])\n",
    "plt.plot(history2.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6TrQ1iKnDwmn",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Prediction\n",
    "\n",
    "Use both trained model to predict the fist image of the testset for five times, and describe what you observe?  \n",
    "Do the same for an image that was not used during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HivDSrlc03u5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#predict the same image gives the same result\n",
    "#here for known label\n",
    "print(labels[y_test[0]])\n",
    "for i in range(0,5):\n",
    "  print(np.round(model.predict(x_test[0].reshape(1,32,32,3)),3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H_tPWEl-VB7G",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#predict the same image does not give the same result\n",
    "#here for known label\n",
    "print(labels[y_test[0]])\n",
    "for i in range(0,5):\n",
    "  print(np.round(model_mc.predict(x_test[0].reshape(1,32,32,3)),3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UNFnBcXo03u-",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#predict the same image does not give the same result\n",
    "#here for unknown label\n",
    "print(labels[y_test[2500]])\n",
    "for i in range(0,5):\n",
    "  print(np.round(model.predict(x_test[2500].reshape(1,32,32,3)),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yz3dzY6hVKx6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#predict the same image does not give the same result\n",
    "#here for unknown label\n",
    "print(labels[y_test[2501]])\n",
    "for i in range(0,5):\n",
    "  print(np.round(model_mc.predict(x_test[2501].reshape(1,32,32,3)),3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-vxn0mzwSbC",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's calculate the accuracy for the model without dropout at test time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EjMbccv1bKdv",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "preds = model.predict(x_test)\n",
    "np.average(np.argmax(preds,axis=1)==y_test.flatten())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7gCYuC8Sxep9",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we will extract all predicted probabilities for all the test images for both models. In the model with dropout at testtime we will predict each image for multiple times (50) and then take the average of these predicted probabilities for the final prediction. Finally we will use those probabilities as a certainty messure and compare the two models. For the unknown classes we would expect to have a lower certainty than for the known clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CbQZm4VtVSUZ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "preds_mc=np.zeros((len(x_test),5))\n",
    "for i in tqdm(range(0,len(x_test))):\n",
    "  multi_img=np.tile(x_test[i],(50,1,1,1))\n",
    "  preds_mc[i]=np.mean(model_mc.predict(multi_img),axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z-8C3_cSyudO",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's calculate the accuracy for the model with dropout at test time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7mN2OUqNb48n",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.average(np.argmax(preds_mc,axis=1)==y_test.flatten())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "crgIXjL2gYvW",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's have a closer look whats happening. We plot the probabilities of the classification for each class below. Rememeber that we've trained on the first 5 classes only!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q6Up9EmVYb_T",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "preds_mc_ = np.zeros((10,len(x_test)//10,5))\n",
    "for i in range(0,10):\n",
    "  preds_mc_[i] = preds_mc[np.where(y_test==i)[0]]\n",
    "\n",
    "preds_ = np.zeros((10,len(x_test)//10,5))\n",
    "for i in range(0,10):\n",
    "  preds_[i] = model.predict(x_test[np.where(y_test==i)[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "URIsWJY4Y_2Q",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(26,10))\n",
    "for i in range(0,10):\n",
    "  plt.subplot(2,5,i+1)\n",
    "  plt.hist(np.max(preds_[i],axis=1),alpha=0.3,color=\"blue\",label=\"normal\", bins=20)\n",
    "  plt.hist(np.max(preds_mc_[i],axis=1),alpha=0.3,color=\"red\",label=\"MC dropout\", bins=20)\n",
    "  plt.legend()\n",
    "  plt.title(labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjZ39Ad7fueU",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Now it's your turn\n",
    "\n",
    "* Caluclate the accuracy for both approaches when specifiyng a minimal confidence value. How many instances can be classified?\n",
    "* Try to improve the model by playing with the hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hs0jUMishmAW",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "minConfidence = 0.95\n",
    "\n",
    "preds_thr = preds[np.where(np.max(preds, axis=1)> minConfidence)]\n",
    "y_test_thr = y_test[np.where(np.max(preds, axis=1)> minConfidence)]\n",
    "preds_mc_thr = preds_mc[np.where(np.max(preds_mc, axis=1)> minConfidence)]\n",
    "y_test_mc_thr = y_test[np.where(np.max(preds_mc, axis=1)> minConfidence)]\n",
    "\n",
    "print (\"normal:     \", np.average(np.argmax(preds_thr,axis=1)==y_test_thr.flatten()), '(#', len(y_test_thr),\")\")\n",
    "print (\"MC dropout: \", np.average(np.argmax(preds_mc_thr,axis=1)==y_test_mc_thr.flatten()), '(#', len(y_test_mc_thr),\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WjipQDAGMY0N"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "07_cifar10_not_all_labels_MC.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
