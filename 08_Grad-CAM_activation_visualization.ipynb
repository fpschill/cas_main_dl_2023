{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDbjiI_JJ33q"
      },
      "source": [
        "# Grad-CAM class activation visualization\n",
        "\n",
        "In this notebook were going to have a look at Gradient-weighted Class Activation Mapping (Grad-CAM). This a technique to produce \"visual explanations\" for decisions from a large class of CNN-based models. The Grad-CAM algorithm provides a heatmap of the important regions for a given decision (e.g. class activation heatmap for an image classification model) of an image.\n",
        "\n",
        "This notebook is based on https://keras.io/examples/vision/grad_cam/ from [fchollet](https://twitter.com/fchollet). <br>\n",
        "More information about Grad-CAM can be found under: https://arxiv.org/abs/1610.02391.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ec3OBLPRJ33x"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVs_gwgFJ33z"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "# Display\n",
        "from IPython.display import Image, display\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPp8paEJJ332"
      },
      "source": [
        "## Configurable parameters\n",
        "\n",
        "After the needed packages are imported were going to import the pretrained \"Xception\" model (pretrained on imagenet). This model takes images with a size of 299x299x3. Also were going to import a random picture.\n",
        "\n",
        "To get the values for `last_conv_layer_name` use `model.summary()`\n",
        "to see the names of all layers in the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSiEQDlyu4Ys"
      },
      "outputs": [],
      "source": [
        "model_builder = keras.applications.xception.Xception\n",
        "img_size = (299, 299)\n",
        "preprocess_input = keras.applications.xception.preprocess_input\n",
        "decode_predictions = keras.applications.xception.decode_predictions\n",
        "\n",
        "#model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ffRqsCpJ334"
      },
      "outputs": [],
      "source": [
        "\n",
        "last_conv_layer_name = \"block14_sepconv2_act\"\n",
        "\n",
        "# Make model\n",
        "model = model_builder(weights=\"imagenet\")\n",
        "\n",
        "# Remove last layer's softmax\n",
        "model.layers[-1].activation = None\n",
        "\n",
        "# The local path to our target image\n",
        "img_path = keras.utils.get_file(\n",
        "    \"african_elephant.jpg\", \"https://i.imgur.com/Bvro0YD.png\"\n",
        ")\n",
        "\n",
        "# img_path = keras.utils.get_file(\n",
        "#     origin = \"https://dinosours.files.wordpress.com/2015/09/img_4952.jpg\"\n",
        "# )\n",
        "\n",
        "display(Image(img_path))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7uywBDDJ337"
      },
      "source": [
        "## The Grad-CAM algorithm\n",
        "\n",
        "Now were going to define 2 functions. One for transforming the images into the correct size. The other for generating the class activation heatmap."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_UD5WSLlJ339"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_img_array(img_path, size):\n",
        "    # `img` is a PIL image of size 299x299\n",
        "    img = keras.preprocessing.image.load_img(img_path, target_size=size)\n",
        "    # `array` is a float32 Numpy array of shape (299, 299, 3)\n",
        "    array = keras.preprocessing.image.img_to_array(img)\n",
        "    # We add a dimension to transform our array into a \"batch\"\n",
        "    # of size (1, 299, 299, 3)\n",
        "    array = np.expand_dims(array, axis=0)\n",
        "    return array\n",
        "\n",
        "\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
        "    # First, we create a model that maps the input image to the activations\n",
        "    # of the last conv layer as well as the output predictions\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "\n",
        "    # Then, we compute the gradient of the top predicted class for our input image\n",
        "    # with respect to the activations of the last conv layer\n",
        "    with tf.GradientTape() as tape:\n",
        "        last_conv_layer_output, preds = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(preds[0])\n",
        "        class_channel = preds[:, pred_index]\n",
        "\n",
        "    # This is the gradient of the output neuron (top predicted or chosen)\n",
        "    # with regard to the output feature map of the last conv layer\n",
        "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
        "\n",
        "    # This is a vector where each entry is the mean intensity of the gradient\n",
        "    # over a specific feature map channel\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    # We multiply each channel in the feature map array\n",
        "    # by \"how important this channel is\" with regard to the top predicted class\n",
        "    # then sum all the channels to obtain the heatmap class activation\n",
        "    last_conv_layer_output = last_conv_layer_output[0]\n",
        "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "\n",
        "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "    return heatmap.numpy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDlHiszDJ33_"
      },
      "source": [
        "## Let's test-drive it\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhK6b-ISJ34B"
      },
      "outputs": [],
      "source": [
        "# Prepare image\n",
        "img_array = preprocess_input(get_img_array(img_path, size=img_size))\n",
        "\n",
        "# Print what the top predicted class is\n",
        "preds = model.predict(img_array)\n",
        "print(\"Predicted:\", decode_predictions(preds, top=1)[0])\n",
        "\n",
        "# Generate class activation heatmap\n",
        "heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
        "\n",
        "# Display heatmap\n",
        "plt.matshow(heatmap)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXFrzxnFJ34D"
      },
      "source": [
        "## Create a superimposed visualization\n",
        "\n",
        "For better visualization let us create a function to \"lay\" the heatmap over an image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEBVdDWZJ34E"
      },
      "outputs": [],
      "source": [
        "\n",
        "def save_and_display_gradcam(img_path, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n",
        "    # Load the original image\n",
        "    img = keras.preprocessing.image.load_img(img_path)\n",
        "    img = keras.preprocessing.image.img_to_array(img)\n",
        "\n",
        "    # Rescale heatmap to a range 0-255\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "    # Use jet colormap to colorize heatmap\n",
        "    jet = cm.get_cmap(\"jet\")\n",
        "\n",
        "    # Use RGB values of the colormap\n",
        "    jet_colors = jet(np.arange(256))[:, :3]\n",
        "    jet_heatmap = jet_colors[heatmap]\n",
        "\n",
        "    # Create an image with RGB colorized heatmap\n",
        "    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n",
        "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
        "    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n",
        "\n",
        "    # Superimpose the heatmap on original image\n",
        "    superimposed_img = jet_heatmap * alpha + img\n",
        "    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n",
        "\n",
        "    # Save the superimposed image\n",
        "    superimposed_img.save(cam_path)\n",
        "\n",
        "    # Display Grad CAM\n",
        "    display(Image(cam_path))\n",
        "\n",
        "\n",
        "save_and_display_gradcam(img_path, heatmap)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMFu313bJ34G"
      },
      "source": [
        "## Let's try another image\n",
        "\n",
        "We will see how the grad cam explains the model's outputs for a multi-label image. Let's\n",
        "try an image with a cat and a dog together, and see how the grad cam behaves."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbhr4aBdJ34H"
      },
      "outputs": [],
      "source": [
        "img_path = keras.utils.get_file(\n",
        "    \"cat_and_dog.jpg\",\n",
        "    \"https://storage.googleapis.com/petbacker/images/blog/2017/dog-and-cat-cover.jpg\",\n",
        ")\n",
        "\n",
        "display(Image(img_path))\n",
        "\n",
        "# Prepare image\n",
        "img_array = preprocess_input(get_img_array(img_path, size=img_size))\n",
        "\n",
        "# Print what the two top predicted classes are\n",
        "preds = model.predict(img_array)\n",
        "print(\"Predicted:\", decode_predictions(preds, top=2)[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DldDIx4J34I"
      },
      "source": [
        "We generate class activation heatmap for \"chow\",  the class index is 260"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmwIp0cqJ34J"
      },
      "outputs": [],
      "source": [
        "heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=260)\n",
        "\n",
        "save_and_display_gradcam(img_path, heatmap)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgkqJw9aJ34L"
      },
      "source": [
        "We generate class activation heatmap for \"egyptian cat\", the class index is 285"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plLT7DFqJ34L"
      },
      "outputs": [],
      "source": [
        "heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=285)\n",
        "\n",
        "save_and_display_gradcam(img_path, heatmap)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31RDiEX2cdI8"
      },
      "source": [
        "# Now it's your turn\n",
        "\n",
        "* Look up the activation heatmap for 'car mirror', does it make sense? You'll find all labels under: https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a\n",
        "* What happens if instead of a picture of a real elephant you use a picture of an elephant drawing, a plush or a model elephant. Does the activation heatmap still makes any sense? (e.g. https://dinosours.files.wordpress.com/2015/09/img_4952.jpg)\n",
        "* Try to use the algorithm for a picture of your choice\n",
        "* What happens if you change the visualized layer (last_con_layer_name)?\n",
        "* What happens if two objects of the same class are in one image?\n",
        "* Try to use the algorithm for another Convolutional Neural Networ (e.g. VGG Net or your own)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4vr4cb2mwpg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "08_Grad-CAM_activation_visualization.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}